* $n$ Entscheidungsvariablen $x_1,...,x_n$ mit $x_i \in R$ und $n \in N$
* Nicht-lineare Zielfunktion $f(x_1,...,x_n) \rightarrow \min$ 
* (Nicht-)lineare Randbedingungen mit $g_i(x_1,...,x_n) \leq b_i$
* (Nicht-)lineare Randbedingungen mit $h_j(x_1,...,x_n)=b_j$

# Grundlegende Vorgehensweise
## NL Optimierungsprobleme ohne Randbedingungen
Bestimmung der Optima:
1. Ermittle kritische Stellen, die als Optimum in Frage kommen (*Extrema*), also lokale Optima.
2. Überprüfung der lokalen Optima durch Randwert-vergleich auf absolute Optimalität, also globale Optima.

Verwendete Analytische Verfahren:
* Berechnung des Gradienten $\nabla f(x)$ und Bestimmung der kritischen Stellen bei $\nabla f(x)=0$
* Ermittlung der *Hesse-Matrix* $H(x)$ und Prüfung der Definitheit an kritischen Stellen
	* wenn *positiv definit*, dann lokales Minimum
	* wenn *negativ definit*, dann lokales Maximum
	* wenn *indefinit*, dann doch kein lokales Optimum
* Grenzwerte der Funktion bestimmen (wenn die Funktion gegen $-\infty$ abhaut, kann es kein globales Minimum geben).

---
## Mathematische Wiederholung
* Gegeben ist Funktion $f(x_1,...,x_n)$, wie z.B. $f(x_1,x_2,x_3)=x_1*(x_2)^2*\ln(x_3)$ 
* Partielle Ableitung ist notwendig, da nach mehreren Parametern abgeleitet werden kann
$$\frac{\partial f}{\partial x_i}=\lim_{h \to 0}\frac{f(x_1,...,x_i+h,x_n)-f(x_1,...,x_i,...,x_n)}{h}$$
* Erste Ableitungen lassen sich zu einem Vektor anordnen, dem *Gradienten* $\nabla f$ . Für das Beispiel ist um Punkt $(2, -1, e)$ der Gradient
$$
\nabla f=
\begin{bmatrix} 
	\frac{\partial f}{\partial x_1} \\ 
	\vdots \\ 
	\frac{\partial f}{\partial x_n} 
\end{bmatrix}=
\begin{bmatrix}
	(x_2)^2\ln(x_3) \\
	2x_1x_2\ln(x_3) \\
	\frac{x_1(x_2)^2}{x_3}
\end{bmatrix}=
\begin{bmatrix}
	1 \\ -4 \\ \frac{2}{e}
\end{bmatrix}
$$
* Man berechnet $\nabla f=0$, um einen Extrempunkt zu ermitteln. Für das Beispiel ist das $(1,0,e)$
* Um die Krümmung zu bestimmen, würde man die 2. Ableitung des Gradienten verwenden. Daraus kann man die Hesse-Matrix bauen, siehe $i$ und $j$.
$$
\frac{\partial^2 f}{\partial x_i \partial x_j} = 
\begin{bmatrix}
	\frac{\partial^2 f}{\partial x_1 \partial x_1} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
	\vdots & \ddots & \vdots \\
	 \frac{\partial^2 f}{\partial x_n \partial x_1} & \cdots & \frac{\partial^2 f}{\partial x_n \partial x_n}
\end{bmatrix} =
\begin{bmatrix}
	0 & 2x_2\ln(x_3) & \frac{(x_2)^2}{x_3} \\
	2x_2\ln x_3 & 2x_1 \ln x_3 & \frac{2x_1x_2}{x_3} \\
	\frac{(x_2)^2}{x_3} & \frac{2x_1x_2}{x_3} & \frac{-x_1(x_2)^2}{(x_2)^2}
\end{bmatrix}
$$
Die Definitheit der Hesse-Matrix ermittelt man durch die Eigenwerte
* Alle Eigenwerte positiv: positiv definit
* Alle Eigenwerte negativ: negativ definit
* Gemischte Eigenwerte: Indefinit

oder durch das Sylvester Kriterium: Berechnung der Haupt-Minoren $H_1,...,H_n$ der Matrix 
* $x$ aller Haupt-Minoren positiv: positiv definit
* $x$ aller Haupt-Minoren negativ: negativ definit
* Gemischt: Indefinit

---

## Erweitertes Vorgehen für Randbedingungen
### Nur mit Gleichheit-Randbedingungen
* Einbezug von **Gleichheit-Randbedingungen** durch die *Lagrange*-Methode (Zusammenfassung der Zielfunktion und Randbedingungen zu einer einzigen Funktion). Diese wird auch bei neuronalen Netzen verwendet.

1. Aufstellen der Lagrange-Funktion $L(x, \lambda)$
2. Bestimmung der Extrema von $L(x,\lambda)$
3. Bestimmung Minimum/Maximum für $L(x)$ mit berechnetem $\lambda$.

--- 
Aufstellen der Lagrange-Funktion
* Gegeben: $f(x)$ mit $x \in R^n$ und $k$ Gleichheit-Randbedingungen $h$
$$ L(x, \lambda)=f(x)+\sum^k_{i=1}{\lambda_i h_i(x)};\; \lambda \in R^n $$
--- 

### Wenn auch Ungleichheit-Randbedingungen erlaubt sind
* Aussortierung von inaktiven Randbedingungen, die keine Auswirkung auf das Optimum haben. 
	* Inaktive Randbedingungen werden fallen gelassen.
	* Aktive Randbedingungen werden als Gleichheit-Randbedingungen in der Lagrange-Funktion berücksichtigt.
* Eine Ungleichung ist aktiv, wenn wir auf dem Weg zum Extremum an die obere Grenze der Ungleichung stoßen (i.e. die Ungleichung eine einschränkende Wirkung entfaltet).

![[Aktive-Inaktive-Randbedingungen.svg]]
* **Schwierigkeit**: Man weiß nicht, welche Randbedingungen aktiv oder inaktiv sind, d.h. man muss zuerst die Extrema ermitteln und danach die Randbedingungen hinzunehmen. Hierbei sind viele Kombinationen von aktiven und inaktiven Ungleichungen und Versuche (Trial-and-Error) nötig. Sehr unpraktikabel, da analytisch von Hand gerechnet werden muss.