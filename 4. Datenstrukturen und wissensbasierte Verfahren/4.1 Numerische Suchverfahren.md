Keine mathematisch-bewiesene, analytische Verfahren, sondern *Suchen* (vgl. Trial and Error).
# Deterministische Numerische Suchverfahren
Suchverfahren, die nicht mit Zufall arbeiten.
## Gittersuche
* Gleichmäßige Verteilung von $N$ Testpunkten in Gitter (Suchraum)
* Testpunkt mit kleinstem Zielfunktionswert ergibt berechnetes Optimum

> [!WARNING] Ungenauigkeit
> * Optimum kann zwischen den diskreten Gitterpunkten liegen, aber eine Annäherung ist immer noch besser als gar kein Optimum.
> * Das *berechnete Optimum* ist also nicht das *tatsächliche Optimum*

### Intervallsuche
![[Intervallsuche.svg]]
Der Interval $l=\frac{b-a}{N+1}$ muss berechnet werden
* Mehr Intervalle = Mehr Rechenaufwand, aber mehr Genauigkeit

### Intervall-Schachtelung
* Rekursive, äquidistante Unterteilung des Test-Intervalls, das den besten Testpunkt enthält in erneute $N$ Testpunkte.
* Trotz der rekursiven Unterteilung, kann man das Optimum verfehlen.
![[Intervalschachtelung.svg]]
1. $l_1=b-a$
2. $l_2=0.5(b-a)$
3. $l_3=0.5 * 0.5*(b-a)$
4. ...

### Fibonacci-Suche
* Überlappende Teilintervalle für $N$ Schritte so gewählt, dass pro Iteration nur 1 Testpunkt-Auswertung notwendig ist.
* Fibonacci-Folge: $f_0=f_1=1$ und die Folge ist definiert als $f_k=f_{k-1}+f_{k-2}$, wie z.B. $1,1,2,3,5,8,13,...$.
* Schrittweite bei der Verkleinerung des Intervalls orientiert sich an der Fibonacci Folge: $s_k=\frac{f_{N-(k+1)}}{f_{N-k}}(b_k-a_k)$ 
* Die Testpunkte ergeben sich aus $c_k=a_k+s_k$ und $d_k=b_k-s_k$
![[Fibonacci.svg]]
Berechnung der neuen $a_k$ und $b_k$ für den nächsten Schritt:
* Falls $f(d_k)>f(c_k) \rightarrow a_{k+1}=d_k; \; b_{k+1}=b_k$
* Falls $f(d_k) \leq f(c_k) \rightarrow a_{k+1}=a_k; \; b_{k+1}=c_k$

## Suche mit *Regula Falsa*
> [!WARNING] Einschränkungen
> * Funktion muss differenzierbar sein (wenn Ableitung nicht gegeben)
> * Nur bei 1-D Funktionen gut anwendbar

> [!INFO] Problem bei mehreren Optima zwischen den Werten
> Es kann passieren, dass deswegen die beiden Ableitungen dasselbe Vorzeichen haben. Dann muss man aufhören und es ist nicht lösbar

* Einfaches iteratives Interpolationsverfahren unter Ausnutzung der Zwischenwertsatzes.
> Zwischenwertsatz: *Ist die 1. Ableitung zwischen 2 Punkten positiv und negativ, so muss dazwischen ein Extrempunkt sein.*
* Gegeben sind Ausgangspunkte $a_k$ und $b_k$ mit $f'(a_k)$ und $f'(b_k)$ unterschiedlicher Vorzeichen

Sekante: $f'(c_k)=f'(a_k)+\frac{f'(b_k)-f'(a_k)}{b_k-a_k}(c_k-a_k)$
$f'(c_k) = 0$ daraus ergibt sich $c_k=a_k-f'(a_k)\frac{b_k-a_k}{f'(b_k)-f'(a_k)}$

![[RegulaFalsa.svg]]

Iterative Berechnung: $a_{k+1}$ und $b_{k+1}$:
* Falls $f'(c_k)$ und $f'(a_k)$ gleiches Vorzeichen: $a_{k+1}=c_k$ und $b_{k+1}=b_k$
* Falls $f'(c_k)$ und $f'(b_k)$ gleiches Vorzeichen: $a_{k+1}=a_k$ und $b_{k+1}=c_k$ 

Terminierung sobald $f'(c_k)$ kleiner einer Genauigkeit.

## Alternativ: Newton Verfahren
* Tangenten von $f'(x_n)$ schneiden mit der x-Achse und bildet dort $x_{n+1}$. Iterativ fortgeführt nähert es sich der Nullstelle von $f'(x)$ an.