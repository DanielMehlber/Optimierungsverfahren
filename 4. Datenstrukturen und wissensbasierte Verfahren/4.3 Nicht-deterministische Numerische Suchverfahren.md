Zufällige Bestimmung von Testpunkten im Suchraum

> [!WARNING] Vorsicht
> Praxisrelevant, obwohl Vorbehalte gegenüber der Qualität der gefundenen Optima begründet sind.

# Evolutionäre Algorithmen
* Grundlage ist die Moderne Evolutionstheorie (Wolf & Darwin): Zeigt wie sich neue Arten (Individuen) aus vorausgehenden Arten durch Rekombination, Variation und Selektion entwickeln 
	* Rekombination erfolgt während der Fortpflanzung (Reproduktion).
	* Variation erfolgt durch zufällige, meist relativ geringe Veränderung des Erbguts (Mutation).
	* Selektion erfolgt durch die Ausfilterung der schlechteren Arten (*Survival of the Fittest*).
## Evolutionsstrategien
Nichtdeterministisches Numerischen Suchverfahren mit 
* $x_{k+1}=x_k+z_k$, wobei $z_k$ einer Normalverteilung $z_{k,i}=N(0, \delta^2); \; i=1,..,n$ entspricht und die zufällige Schrittweite darstellt. Die Schrittweite sollte zu Beginn hoch (viel Varianz) und zu Ende eher gering sein.
* Mindestgüte $G \in R$ (End-Bedingung, dieses Minimum muss erreicht werden in der Kostenfunktion; Man kann auch die Leistung maximieren).
* Generationen: Iteration über $k$ solange bis $f(x_k) \leq G$ (Lösungskandidaten).
* **Rekombination**: Erzeugung von Nachkommen aus Elternpaaren durch Mischen der Elemente
	* Diskrete Rekombination: Grenze im Vektor wird festgelegt und die beiden Eigenschaftsvektoren an dieser Stelle überschrieben, z.B. 50-50.
	* Intermediäre Rekombination: z.B. Wählen von Mittelwert der Eigenschaften.
	* Mehrpunkt Rekombination: Zufällige Bestimmung der Rekombinationsstellen (z.B. mit einem zufälligen binären Maskenvektor, der angibt, wie das neue Individuum aus den beiden Elternpaaren generiert wird)
* **Mutation**: Zufällige Änderung der Entscheidungsvariable durch $z_k$ mit einer Varianz $\delta$ (Schrittweise).
	* Jede Stelle wird mit einer bestimmten Wahrscheinlichkeit $p$ geändert. Für jede Stelle wird eine gleichverteilte Zufallszahl $z \in [0,1]$ erzeugt. Falls $z \leq p$ wird die Stelle geändert.
* **Selektion**: Falls $f(x_{k+1}) > f(x_k)$, dann wird $x_{k+1}=x_k$
	* Mit Aussterben der Eltern
	* Ohne Aussterben der Eltern
* Standardabweichung $\sigma$ können für jedes Element $x_i$ individuell festgelegt werden $\rightarrow \sigma_{k,i}$.

## Abbruch-Kriterium
* Abbruchkriterium über Wert der Zielfunktion $f(x) \leq G$ bei flachem $f(x_k)$ ungünstig. Besser: Abnahme des Zielfunktionswerts über mehrere Iterationen. Terminierung, sobald Zielfunktionswert über mehrere Iterationen nicht weiter abnimmt.
## Genetische Programmierung
* Für Codierung und Mutation von Werten
* Kann zu instabilen Mutationen führen: z.B. bei Binärsystem können Mutationen der höheren Bits heftige Mutationen hevorrufen.
---
Basiert auf genetischen Informationen in der Natur: Doppelhelix der DNS (*gespeichert* in Basenpaaren aus **A**denin, **C**ytosin, **G**uanin & **T**hymin)
* Mögliche Basenpaare sind AT, TA, GC, CG
* Basenpaare werden verkettet und damit die Erbinformationen codiert
---
* Genetische Codierung zur Darstellung von reellen Zahlen, logische Ausdrücke und Operatorfolgen.
	* Binärcode: $64_{10}=01000000_2$. Problem: Mutation ist nicht an allen Stellen gleichwertig
	* Gray-Codes (für gleichwertigere Mutationen): Alternative *Zählweise* im Binären Zahlensystem
		* Binär: $0000 \rightarrow 0001 \rightarrow 0010 \rightarrow 0011 \rightarrow 0100 \rightarrow \; ...$
		* Gray: $0000 \rightarrow 0001 \rightarrow 0011 \rightarrow 0010 \rightarrow 0110 \rightarrow \; ...$

# Partikel-filter
* Anwendung bei Optimierung der berechneten Fahrzeugsposition in einer Karte unter Verwendung der Daten eines Laser-Scanners.
* Fokus ist die *Selbst-Lokalisation*
	* Scan $t$ ist der Referenz-Scan der Karte
	* Scan $s$ ist der aktuelle Scan
	* Gesucht ist die Lokalität $l=(x,y,th)$ auf der Karte, wobei $th$ die Orientierung des Sensorträgers ist.
	* $p(l)$ ist die Wahrscheinlichkeit mit der sich das Fahrzeug an Position $l$ befindet. $p(l) \in [0,1]$
--- 
* Verwendet z.B. zur Selbst-Lokalisation bei Selbstfahrenden Autos

![[Pasted image 20231122110624.png]]

* Laserscanner tasten als Entfernungsmesser mit Lichtstrahlen die Umgebung ab (z.B. Drehender Sensor).
* Daraus ergeben sich *Wolken* aus gemessenen Punkten.
* Die verschiedenen Lichtstrahlen können anhand ihrer Länge oder Phase unterschieden werden.
---

Ziel ist es den Punkt $p(l) \rightarrow \max$ zu finden.
* Zählung der Überdeckungspunkte ein einem Raster
* Verschiebung und Verdrehung der potentiellen Fahrzeugpositionen im mehrdimensionalen Raum, bis die Anzahl der Überdeckungspunkte zwischen $s$ und $t$ maximal ist.
$\Rightarrow$ Hierbei handelt es sich um ein Optimierungsproblem, da das Problem NP-vollständig ist.

Vereinfachung der Optimierungsproblems durch Annahmen
* Gauß'sche Positionsverteilung, sodass die Wahrscheinlichkeitsrechnung angewandt werden kann (Erwartungswert ist Position $l$, Varianz, ...).
* Lokalitätsannahme, i.e. man weiß ungefähr wo sich das Fahrzeug befindet (z.B. durch Tracking)

Suche von $p(l)_{\max}$ trotz Lokalitätsannahme wegen Echtzeitbedingung nicht durch vollständige Enumeration (einfache for-Schleife) möglich. Die Lösung ist der Einsatz von *Partikel Filter*.

Idee: 
1. Zufällige Streuung von Partikeln (=Lokalitätshypothesen) um die Lokalitätsannahme herum.
2. Berechnung von $p$ für jeden Partikel
3. $l$ und höchstes berechnetes $p(l)$ ergibt neue Lokalitätsannahme
4. Echtzeitbedingung legt fest, wie oft man Partikel streuen kann (Wiederholung des Verfahrens)

## Markov Lokalisation
Einbindung der Partikelfilter
1. Berechnung von $l=(\mu,\Sigma)$ anhand Lokalitätsannahme  $\mu=(x,y,\theta)$ und Erwartungswert $\Sigma=\begin{bmatrix} \delta_x^2 & \delta_{x,y} & \delta_{x,th} \\ \delta_{y,x} & \delta_{y}^2 & \delta_{y,th} \\ \delta_{th,x} & \delta_{th,y} & \delta_{th}^2\end{bmatrix}$ (Kovarianzmatrix).
2. Anwendung von Partikelfilter n-te Streuung für eine genauere Positionsabschätzung
3. (Fehlt) Generierung der Positionsabschätzung in eine Ellipse.